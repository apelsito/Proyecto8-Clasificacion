# AnÃ¡lisis y Modelado: PredicciÃ³n de Precios de Casas ğŸ 

# DescripciÃ³n del Proyecto ğŸ’¡

Este proyecto tiene como objetivo desarrollar un modelo predictivo capaz de estimar el precio de propiedades inmobiliarias en Madrid, utilizando un conjunto de datos real con 40 columnas. Estas columnas incluyen informaciÃ³n clave sobre las propiedades, como su tamaÃ±o, ubicaciÃ³n, nÃºmero de habitaciones, tipo de propiedad y mÃ¡s. 

El propÃ³sito principal es ofrecer una herramienta Ãºtil para agentes inmobiliarios, compradores y vendedores, que permita tomar decisiones mÃ¡s informadas basadas en datos.

## ğŸ¯ Objetivo
1. **Carga y ExploraciÃ³n de Datos**:
   - Identificar patrones en los datos.
   - Detectar valores atÃ­picos y posibles inconsistencias.

2. **Preprocesamiento**:
   - Limpieza y preparaciÃ³n de datos.
   - CodificaciÃ³n de variables categÃ³ricas.
   - Escalado de variables numÃ©ricas.
   - GestiÃ³n de valores nulos y outliers.

3. **Modelado**:
   - Entrenamiento de mÃºltiples modelos de Machine Learning.
   - EvaluaciÃ³n de su desempeÃ±o utilizando mÃ©tricas como RMSE y RÂ².

4. **VisualizaciÃ³n**:
   - Mostrar grÃ¡ficamente la importancia de las variables.
   - Analizar los errores y predicciones del modelo.

5. **OptimizaciÃ³n**:
   - Ajustar hiperparÃ¡metros para maximizar la precisiÃ³n del modelo.

## Estructura del Proyecto ğŸ—‚ï¸

```bash
Proyecto7-PrediccionCasas/
â”œâ”€â”€ datos/                      # Archivos de datos CSV y PKL para el proyecto.
â”‚   â”œâ”€â”€ lista_opciones/         # Lista de opciones para los menÃºs de streamlit.
â”‚   â”œâ”€â”€ modelos-encoders/       # Lista de PKLs de los modelos y encoders ya entrenados.
â”‚
â”œâ”€â”€ jupyter_notebooks/          # Notebooks de Jupyter con los modelos probados.
â”‚   â”œâ”€â”€ Modelo X/               # Carpeta del modelo
â”‚   â”‚   â”œâ”€â”€ 00_Sobre_El_Modelo.md
â”‚   â”‚   â”œâ”€â”€ 01_eda_inicial.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_gestion_nulos.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_eda_sin_nulos.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_encoding.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_feature_scaling.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_gestion_outliers.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_regresion_lineal.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_decision_tree.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_gradient_boosting.ipynb
â”‚   â”‚   â”œâ”€â”€ 10_XGBoost.ipynb
â”‚ 
â”œâ”€â”€ src/                        # Archivos .py para funciones auxiliares del proyecto.
â”‚
â”œâ”€â”€ streamlit/                  # Web para realizar predicciones de forma rÃ¡pida y bonita
â”‚    â”œâ”€â”€ main.py                # ConfiguraciÃ³n Web
â”‚    â”œâ”€â”€ prueba_modelo.ipynb 
â”‚
â””â”€â”€ README.md                   # DescripciÃ³n del proyecto, instrucciones de instalaciÃ³n y uso.
```
# InstalaciÃ³n y Requisitos ğŸ› ï¸

## Requisitos

Para ejecutar este proyecto, asegÃºrate de tener instalado lo siguiente:

- **Python 3.x** ğŸ
- **Jupyter Notebook** ğŸ““ para ejecutar y visualizar los anÃ¡lisis de datos
- **Bibliotecas de Python**:
    - [pandas](https://pandas.pydata.org/docs/) para manipulaciÃ³n y anÃ¡lisis de datos ğŸ§¹
    - [numpy](https://numpy.org/doc/stable/) para cÃ¡lculos numÃ©ricos y manejo de matrices ğŸ”¢
    - [matplotlib](https://matplotlib.org/stable/index.html) para crear grÃ¡ficos bÃ¡sicos ğŸ“Š
    - [seaborn](https://seaborn.pydata.org/) para visualizaciones estadÃ­sticas avanzadas ğŸ“ˆ
    - [tqdm](https://tqdm.github.io/) para mostrar barras de progreso en procesos largos â³
    - [xgboost](https://xgboost.readthedocs.io/) para la implementaciÃ³n de modelos basados en Gradient Boosting ğŸŒŸ
    - [scikit-learn](https://scikit-learn.org/stable/) para modelado predictivo y preprocesamiento, incluyendo:
        - `LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`, y `XGBRegressor` para tareas de regresiÃ³n
        - `train_test_split`, `GridSearchCV`, `KFold`, `LeaveOneOut` y `cross_val_score` para particiÃ³n de datos y validaciÃ³n de modelos
        - `StandardScaler` para el escalado de variables
        - MÃ©tricas como `r2_score`, `mean_squared_error`, `mean_absolute_error` para evaluar los modelos
    - [pickle](https://docs.python.org/3/library/pickle.html) para serializar y cargar modelos y objetos ğŸ› ï¸

## ConfiguraciÃ³n Adicional

- Configura `pd.options.display.float_format` para un formato mÃ¡s claro en los valores flotantes.
- AÃ±ade rutas personalizadas al sistema usando `sys.path.append` para facilitar el acceso a los mÃ³dulos personalizados del proyecto.

## InstalaciÃ³n ğŸ› ï¸

1. Clona este repositorio para visualizarlo en vscode:
```bash
git clone https://github.com/apelsito/Proyecto8-Clasificacion
cd Proyecto8-Clasificacion
```
# Resumen de lo realizado en el Modelo final: 

## Fase 1: AnÃ¡lisis Inicial
   - Se realiza un eda inicial
---
## Fase 2: GestiÃ³n Datos
### Se gestionan los datos, eliminando:
- Columna EmployeeID

### Se eliminan duplicados
- Tras eliminar EmployeeID surgieron los duplicados
- Al verlos, los datos coincidian en categorÃ­as que descartaba la idea de que fueran coincidencias que pudieran ocurrir
### Se gestionan los datos, eliminando:
- Columna EmployeeCount
- StandardHours
- Over18
- PerformanceRating

### Se vuelven de numÃ©ricas a categÃ³ricas:
- Education
- JobLevel
- StockOptionLevel
- TrainingTimesLastYear
- JobInvolvement
- PercentSalaryHike
- DistanceFromHome

### Se gestionan los nulos de:
- NumCompaniesWorked
- EnvironmentSatisfaction
- JobSatisfaction
- WorkLifeBalance
- Se eliminan las filas nulas donde Attrition era "NO"

- Se rellena mediante **IterativeImputer** con **RandomForest** las filas con nulos donde **Attrition** fuera "Yes"

- Se redondea el valor rellenado al mÃ¡s cercano, al ser una categorÃ­a no podÃ­an ser decimales

- Se categorizan tras gestionar los nulos de:
   - NumCompaniesWorked
   - EnvironmentSatisfaction
   - JobSatisfaction
   - WorkLifeBalance
---

---
### Fase 4 Encoding
- Se realiza el encoding de las columnas categÃ³ricas:
    - Target Encoder para Ordinales
    - OneHot Encoder para Nominales
---
### Fase 5: Feature Scaling
   - Se realiza Robust Scaler
---
### Fase 6: GestiÃ³n Outliers
   - No se tocan los Outliers
---
### Fase 7: Desbalanceo
- Se realiza **smotenc** incluyendo categorÃ­as para evitar generar nuevas

### Fase 8: EjecuciÃ³n y ComparaciÃ³n de Modelos Predictivos
#### Modelos Usados:
- Logistic Regression
- Decision Tree
- Random Forest
- Gradient Boosting
- XGBooster
---
# Resultados del Mejor Modelo (Modelo 4)


# Streamlit
Se ha creado una web con streamlit en local que permite al usuario realizar predicciones sobre un empleado en caso de querer ejecutarla deberÃ¡:

1. abrir la terminal de python
2. ir a la carpeta **streamlit**
3. ejecutar: 
```bash
   streamlit run main.py
```
Se le pedirÃ¡ un correo electrÃ³nico en la consola, puede saltarse el paso si le da enter de nuevo

Se abrirÃ¡ una ventana de su explorador con la web lista para poder usarse.

# Contribuciones ğŸ¤

Las contribuciones a este proyecto son muy bienvenidas. Si tienes alguna sugerencia, mejora o correcciÃ³n, no dudes en ponerte en contacto o enviar tus ideas.

Cualquier tipo de contribuciÃ³n, ya sea en cÃ³digo, documentaciÃ³n o feedback, serÃ¡ valorada. Â¡Gracias por tu ayuda y colaboraciÃ³n!

# Autores y Agradecimientos âœï¸

## Autor âœ’ï¸
**Gonzalo RuipÃ©rez Ojea** - [@apelsito](https://github.com/apelsito) en github

## Agradecimientos â¤ï¸
Quiero expresar mi agradecimiento a **Hackio** y su equipo por brindarme la capacidad y las herramientas necesarias para realizar este proyecto con solo una semana de formaciÃ³n. Su apoyo ha sido clave para lograr este trabajo.
