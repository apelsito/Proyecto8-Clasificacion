

# Proyecto: PredicciÃ³n de RetenciÃ³n de Empleados ğŸ¢

## ğŸ¯ Objetivo

El objetivo principal de este proyecto es construir un modelo de machine learning capaz de predecir si un empleado permanecerÃ¡ en la empresa o decidirÃ¡ marcharse. A travÃ©s de este anÃ¡lisis, se busca identificar patrones y los factores mÃ¡s relevantes que influyen en la retenciÃ³n y rotaciÃ³n del personal, como:

- SatisfacciÃ³n laboral.
- Horas trabajadas.
- Relaciones con los jefes.
- Promociones o aumentos salariales.

AdemÃ¡s de construir un modelo predictivo preciso, el proyecto pretende interpretar los resultados obtenidos para proponer estrategias prÃ¡cticas que ayuden a mejorar la retenciÃ³n de empleados, contribuyendo a crear un entorno laboral mÃ¡s saludable y efectivo.

## Estructura del Proyecto ğŸ—‚ï¸

```bash
Proyecto7-PrediccionCasas/
â”œâ”€â”€ datos/                      # Archivos de datos CSV y PKL para el proyecto.
â”‚   â”œâ”€â”€ lista_opciones/         # Lista de opciones para los menÃºs de streamlit.
â”‚   â”œâ”€â”€ modelos-encoders/       # Lista de PKLs de los modelos y encoders ya entrenados.
â”‚
â”œâ”€â”€ jupyter_notebooks/          # Notebooks de Jupyter con los modelos probados.
â”‚   â”œâ”€â”€ Modelo X/               # Carpeta del modelo
â”‚   â”‚   â”œâ”€â”€ 00_Sobre_El_Modelo.md
â”‚   â”‚   â”œâ”€â”€ 01_eda_inicial.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_gestion_datos.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_eda_gestionado.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_encoding.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_feature_scaling.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_outliers.ipynb
â”‚   â”‚   â”œâ”€â”€ 07_desbalanceo.ipynb
â”‚   â”‚   â”œâ”€â”€ 08_modelos.ipynb
â”‚   â”‚   â”œâ”€â”€ 09_obtener_mejor_modelo.ipynb
â”‚ 
â”œâ”€â”€ src/                        # Archivos .py para funciones auxiliares del proyecto.
â”‚
â”œâ”€â”€ streamlit/                  # Web para realizar predicciones de forma rÃ¡pida y bonita
â”‚    â”œâ”€â”€ main.py                # ConfiguraciÃ³n Web
â”‚    â”œâ”€â”€ prueba_modelo.ipynb 
â”‚
â””â”€â”€ README.md                   # DescripciÃ³n del proyecto, instrucciones de instalaciÃ³n y uso.
```
# InstalaciÃ³n y Requisitos ğŸ› ï¸

## Requisitos

Para ejecutar este proyecto, asegÃºrate de tener instalado lo siguiente:

- **Python 3.x** ğŸ
- **Jupyter Notebook** ğŸ““ para ejecutar y visualizar los anÃ¡lisis de datos
- **Bibliotecas de Python**:
    - [pandas](https://pandas.pydata.org/docs/) para manipulaciÃ³n y anÃ¡lisis de datos ğŸ§¹
    - [numpy](https://numpy.org/doc/stable/) para cÃ¡lculos numÃ©ricos y manejo de matrices ğŸ”¢
    - [matplotlib](https://matplotlib.org/stable/index.html) para crear grÃ¡ficos bÃ¡sicos ğŸ“Š
    - [seaborn](https://seaborn.pydata.org/) para visualizaciones estadÃ­sticas avanzadas ğŸ“ˆ
    - [tqdm](https://tqdm.github.io/) para mostrar barras de progreso en procesos largos â³
    - [xgboost](https://xgboost.readthedocs.io/) para la implementaciÃ³n de modelos basados en Gradient Boosting ğŸŒŸ
    - [scikit-learn](https://scikit-learn.org/stable/) para modelado predictivo y preprocesamiento, incluyendo:
        - `LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`, y `XGBRegressor` para tareas de regresiÃ³n
        - `train_test_split`, `GridSearchCV`, `KFold`, `LeaveOneOut` y `cross_val_score` para particiÃ³n de datos y validaciÃ³n de modelos
        - `StandardScaler` para el escalado de variables
        - MÃ©tricas como `r2_score`, `mean_squared_error`, `mean_absolute_error` para evaluar los modelos
    - [pickle](https://docs.python.org/3/library/pickle.html) para serializar y cargar modelos y objetos ğŸ› ï¸

## ConfiguraciÃ³n Adicional

- Configura `pd.options.display.float_format` para un formato mÃ¡s claro en los valores flotantes.
- AÃ±ade rutas personalizadas al sistema usando `sys.path.append` para facilitar el acceso a los mÃ³dulos personalizados del proyecto.

## InstalaciÃ³n ğŸ› ï¸

1. Clona este repositorio para visualizarlo en vscode:
```bash
git clone https://github.com/apelsito/Proyecto8-Clasificacion
cd Proyecto8-Clasificacion
```
# Resumen de lo realizado en el Modelo final: 

## Fase 1: AnÃ¡lisis Inicial
   - Se realiza un eda inicial
---
## Fase 2: GestiÃ³n Datos
### Se gestionan los datos, eliminando:
- Columna EmployeeID

### Se eliminan duplicados
- Tras eliminar EmployeeID surgieron los duplicados
- Al verlos, los datos coincidian en categorÃ­as que descartaba la idea de que fueran coincidencias que pudieran ocurrir
### Se gestionan los datos, eliminando:
- Columna EmployeeCount
- StandardHours
- Over18
- PerformanceRating

### Se vuelven de numÃ©ricas a categÃ³ricas:
- Education
- JobLevel
- StockOptionLevel
- TrainingTimesLastYear
- JobInvolvement
- PercentSalaryHike
- DistanceFromHome

### Se gestionan los nulos de:
- NumCompaniesWorked
- EnvironmentSatisfaction
- JobSatisfaction
- WorkLifeBalance
- Se eliminan las filas nulas donde Attrition era "NO"

- Se rellena mediante **IterativeImputer** con **RandomForest** las filas con nulos donde **Attrition** fuera "Yes"

- Se redondea el valor rellenado al mÃ¡s cercano, al ser una categorÃ­a no podÃ­an ser decimales

- Se categorizan tras gestionar los nulos de:
   - NumCompaniesWorked
   - EnvironmentSatisfaction
   - JobSatisfaction
   - WorkLifeBalance
---
### Fase 4 Encoding
- Se realiza el encoding de las columnas categÃ³ricas:
    - Target Encoder para Ordinales
    - OneHot Encoder para Nominales
---
### Fase 5: Feature Scaling
- Se realiza Robust Scaler
---
### Fase 6: GestiÃ³n Outliers
- No se tocan los Outliers
---
### Fase 7: Desbalanceo
- Se realiza **smotenc** incluyendo categorÃ­as para evitar generar nuevas
- Se realiza despuÃ©s **tomek**

### Fase 8: EjecuciÃ³n y ComparaciÃ³n de Modelos Predictivos
#### Modelos Usados:
- Logistic Regression
- Decision Tree
- Random Forest
- Gradient Boosting
- XGBooster
---
# Resultados del Mejor Modelo (Modelo 4)
- Mejor modelo XGBooster:
- Tiene un test kappa alto.
- Mantiene un buen equilibrio entre train y test. No es overfitting.
- Es un modelo que es rÃ¡pido y eficiente y nos permite ajustarle parÃ¡metros sin muchos quebraderos de cabeza.

# Streamlit
Se ha creado una web con streamlit en local que permite al usuario realizar predicciones sobre un empleado en caso de querer ejecutarla deberÃ¡:

1. abrir la terminal de python
2. ir a la carpeta **streamlit**
3. ejecutar: 
```bash
   streamlit run main.py
```
Se le pedirÃ¡ un correo electrÃ³nico en la consola, puede saltarse el paso si le da enter de nuevo

Se abrirÃ¡ una ventana de su explorador con la web lista para poder usarse.

# Contribuciones ğŸ¤

Las contribuciones a este proyecto son muy bienvenidas. Si tienes alguna sugerencia, mejora o correcciÃ³n, no dudes en ponerte en contacto o enviar tus ideas.

Cualquier tipo de contribuciÃ³n, ya sea en cÃ³digo, documentaciÃ³n o feedback, serÃ¡ valorada. Â¡Gracias por tu ayuda y colaboraciÃ³n!

# Autores y Agradecimientos âœï¸

## Autor âœ’ï¸
**Gonzalo RuipÃ©rez Ojea** - [@apelsito](https://github.com/apelsito) en github

## Agradecimientos â¤ï¸
Quiero expresar mi agradecimiento a **Hackio** y su equipo por brindarme la capacidad y las herramientas necesarias para realizar este proyecto con solo una semana de formaciÃ³n. Su apoyo ha sido clave para lograr este trabajo.
