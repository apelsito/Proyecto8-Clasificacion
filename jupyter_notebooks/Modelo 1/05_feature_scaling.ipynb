{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para gestionar el feature scaling\n",
    "# -----------------------------------------------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler, RobustScaler\n",
    "\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from src.soporte_graficas import (\n",
    "    boxplot_scaler\n",
    ")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../datos/03_datos_encoded.plk\")\n",
    "df[\"Attrition\"] = df[\"Attrition\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuales escalar\n",
    "- Todas las no binarias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicamos Feature Scaling... Pero ¿Cual?\n",
    "Tenemos los Siguientes pero antes:\n",
    "\n",
    "### ¿Qué importancia tienen los outliers?\n",
    "- **RobustScaler:** Es el mas \"amigable\" con los outliers,genera un rango de 0 a X (depende de cuantos datos tengamos) donde aún manteniendo la distribución los tenemos más juntos, si queremos darles mucho peso es nuestra mejor opción\n",
    "\n",
    "- **StandardScaler:** También es amigable con los outliers, pero genera un rango de 0 a X mucho menos que el anterior, mantiene la distribución, si queremos darles algo de peso a los outliers, este es definitivamente nuestro amigo.\n",
    "\n",
    "- **MinMaxScaler:** Genera un rango de 0 a 1 donde mantiene la distribución original pero está todo mucho más comprimido, aquí los outliers no se van a poder apreciar, así que si no te interesan y tus datos no están normalizados... es tu opción\n",
    "\n",
    "- **Normalizer:** Tus datos están normalizados y no te interesan los outliers?, Está es tu opción, Genera un Rango de -1 a 1 en donde mantiene la distribución (como el resto). Es solo para datos normalizados, algo que veremos poco por aquí... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4322 entries, 0 to 4321\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       4322 non-null   int64  \n",
      " 1   Attrition                 4322 non-null   int64  \n",
      " 2   BusinessTravel            4322 non-null   float64\n",
      " 3   Department                4322 non-null   float64\n",
      " 4   DistanceFromHome          4322 non-null   float64\n",
      " 5   EducationField            4322 non-null   float64\n",
      " 6   JobRole                   4322 non-null   float64\n",
      " 7   MaritalStatus             4322 non-null   float64\n",
      " 8   MonthlyIncome             4322 non-null   int64  \n",
      " 9   NumCompaniesWorked        4322 non-null   float64\n",
      " 10  TotalWorkingYears         4322 non-null   int64  \n",
      " 11  TrainingTimesLastYear     4322 non-null   float64\n",
      " 12  YearsAtCompany            4322 non-null   int64  \n",
      " 13  YearsSinceLastPromotion   4322 non-null   int64  \n",
      " 14  YearsWithCurrManager      4322 non-null   int64  \n",
      " 15  EnvironmentSatisfaction   4322 non-null   float64\n",
      " 16  JobSatisfaction           4322 non-null   float64\n",
      " 17  WorkLifeBalance           4322 non-null   float64\n",
      " 18  JobInvolvement            4322 non-null   float64\n",
      " 19  Education_Bachelor        4322 non-null   float64\n",
      " 20  Education_Below College   4322 non-null   float64\n",
      " 21  Education_College         4322 non-null   float64\n",
      " 22  Education_Doctor          4322 non-null   float64\n",
      " 23  Education_Master          4322 non-null   float64\n",
      " 24  Gender_Female             4322 non-null   float64\n",
      " 25  Gender_Male               4322 non-null   float64\n",
      " 26  JobLevel_Level 1          4322 non-null   float64\n",
      " 27  JobLevel_Level 2          4322 non-null   float64\n",
      " 28  JobLevel_Level 3          4322 non-null   float64\n",
      " 29  JobLevel_Level 4          4322 non-null   float64\n",
      " 30  JobLevel_Level 5          4322 non-null   float64\n",
      " 31  PercentSalaryHike_11 %    4322 non-null   float64\n",
      " 32  PercentSalaryHike_12 %    4322 non-null   float64\n",
      " 33  PercentSalaryHike_13 %    4322 non-null   float64\n",
      " 34  PercentSalaryHike_14 %    4322 non-null   float64\n",
      " 35  PercentSalaryHike_15 %    4322 non-null   float64\n",
      " 36  PercentSalaryHike_16 %    4322 non-null   float64\n",
      " 37  PercentSalaryHike_17 %    4322 non-null   float64\n",
      " 38  PercentSalaryHike_18 %    4322 non-null   float64\n",
      " 39  PercentSalaryHike_19 %    4322 non-null   float64\n",
      " 40  PercentSalaryHike_20 %    4322 non-null   float64\n",
      " 41  PercentSalaryHike_21 %    4322 non-null   float64\n",
      " 42  PercentSalaryHike_22 %    4322 non-null   float64\n",
      " 43  PercentSalaryHike_23 %    4322 non-null   float64\n",
      " 44  PercentSalaryHike_24 %    4322 non-null   float64\n",
      " 45  PercentSalaryHike_25 %    4322 non-null   float64\n",
      " 46  StockOptionLevel_Level 0  4322 non-null   float64\n",
      " 47  StockOptionLevel_Level 1  4322 non-null   float64\n",
      " 48  StockOptionLevel_Level 2  4322 non-null   float64\n",
      " 49  StockOptionLevel_Level 3  4322 non-null   float64\n",
      "dtypes: float64(43), int64(7)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_escalar = [\"BusinessTravel\", \"Department\", \"DistanceFromHome\", \"EducationField\",\n",
    "                 \"JobRole\", \"MaritalStatus\", \"NumCompaniesWorked\", \"TrainingTimesLastYear\",\n",
    "                   \"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\", \"JobInvolvement\"]\n",
    "escalador_robust = RobustScaler()\n",
    "datos_transf_robust = escalador_robust.fit_transform(df[cols_escalar])\n",
    "df_c = pd.DataFrame(datos_transf_robust,columns=df[cols_escalar].columns)\n",
    "df.drop(columns=cols_escalar, inplace=True)\n",
    "df = pd.concat([df_c,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../datos/encoders_y_modelos/robust_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(escalador_robust, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../datos/04_datos_feature_scaled.plk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
